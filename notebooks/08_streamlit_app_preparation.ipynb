{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0fcb809",
   "metadata": {},
   "source": [
    "# 08 - Streamlit App Preparation\n",
    "\n",
    "I prepare the trained model and helper functions for building the SleepSense Streamlit app.  \n",
    "This notebook lets me test sample predictions and confirm everything works smoothly before deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f64fb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports ready and folder structure confirmed\n"
     ]
    }
   ],
   "source": [
    "# I import required libraries and set file paths\n",
    "import os, joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RIDGE_MODEL = \"../models/ridge_model.pkl\"\n",
    "FEATURES_PATH = \"../data/processed/sleepsense_features.csv\"\n",
    "os.makedirs(\"../app\", exist_ok=True)\n",
    "\n",
    "print(\"imports ready and folder structure confirmed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b828892",
   "metadata": {},
   "source": [
    "#### ***Inference: I make sure my environment and paths are set correctly.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae7da5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model and dataset loaded successfully\n",
      "dataset shape: (12000, 45)\n"
     ]
    }
   ],
   "source": [
    "# I load my final Ridge Regression model and the processed dataset\n",
    "model = joblib.load(RIDGE_MODEL)\n",
    "df = pd.read_csv(FEATURES_PATH)\n",
    "\n",
    "print(\"model and dataset loaded successfully\")\n",
    "print(\"dataset shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29767332",
   "metadata": {},
   "source": [
    "#### ***Inference: Both model and dataset are ready for testing.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba1ab47",
   "metadata": {},
   "source": [
    "## ***Extract features used in model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce4fea20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features used in app prediction: ['sleep_deficit', 'digital_fatigue', 'env_stress', 'lifestyle_balance', 'late_snack_effect', 'fatigue_env_interaction', 'is_metro', 'avg_sleep_hours', 'screen_time_hours', 'stress_level', 'physical_activity_min', 'age', 'family_size']\n"
     ]
    }
   ],
   "source": [
    "# I identify which features the Ridge model was trained on\n",
    "feature_cols = [\n",
    "    'sleep_deficit','digital_fatigue','env_stress','lifestyle_balance',\n",
    "    'late_snack_effect','fatigue_env_interaction','is_metro',\n",
    "    'avg_sleep_hours','screen_time_hours','stress_level',\n",
    "    'physical_activity_min','age','family_size'\n",
    "]\n",
    "\n",
    "feature_cols = [f for f in feature_cols if f in df.columns]\n",
    "print(\"features used in app prediction:\", feature_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b562e1bd",
   "metadata": {},
   "source": [
    "#### ***Inference: These are the exact columns my app will need for user input.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d8779b",
   "metadata": {},
   "source": [
    "## ***Creating helper function for prediction***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a89f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I define a function that accepts a dictionary of inputs and returns predicted sleep quality\n",
    "def predict_sleep_quality(input_data: dict):\n",
    "    \"\"\"\n",
    "    I take input_data (a dictionary), convert it to a DataFrame,\n",
    "    ensure all required columns exist, and return predicted sleep quality score.\n",
    "    \"\"\"\n",
    "    # make dataframe from single record\n",
    "    x_input = pd.DataFrame([input_data])\n",
    "    \n",
    "    # add any missing columns with 0 (in case city or category not provided)\n",
    "    for col in feature_cols:\n",
    "        if col not in x_input.columns:\n",
    "            x_input[col] = 0\n",
    "    \n",
    "    # reorder columns to match training\n",
    "    x_input = x_input[feature_cols]\n",
    "    \n",
    "    # predict sleep quality\n",
    "    prediction = model.predict(x_input)[0]\n",
    "    return round(prediction, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4829ca62",
   "metadata": {},
   "source": [
    "### ***Comment:***\n",
    "* ***This function is what the Streamlit app will use for real-time prediction.***\n",
    "\n",
    "* ***Inference: I can now pass user-like data and instantly get predicted sleep quality.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1ca8ef",
   "metadata": {},
   "source": [
    "## ***Test sample prediction (example)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57a317f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sleep Quality Score: 15.67\n"
     ]
    }
   ],
   "source": [
    "# I test the model with a custom example input\n",
    "sample_input = {\n",
    "    \"age\": 28,\n",
    "    \"family_size\": 4,\n",
    "    \"work_hours\": 9,\n",
    "    \"avg_sleep_hours\": 7,\n",
    "    \"screen_time_hours\": 5,\n",
    "    \"tea_cups\": 2,\n",
    "    \"coffee_cups\": 1,\n",
    "    \"late_snack\": 1,\n",
    "    \"spice_intake\": 2,\n",
    "    \"religious_freq\": 3,\n",
    "    \"festival_freq\": 1,\n",
    "    \"physical_activity_min\": 40,\n",
    "    \"bedtime_variability\": 2,\n",
    "    \"stress_level\": 5,\n",
    "    \"city_noise_dB\": 60,\n",
    "    \"light_pollution_index\": 70,\n",
    "    \"air_quality_index\": 90,\n",
    "    \"sleep_deficit\": -0.5,\n",
    "    \"digital_fatigue\": 0.8,\n",
    "    \"env_stress\": 0.7,\n",
    "    \"lifestyle_balance\": -0.2,\n",
    "    \"late_snack_effect\": 0.3,\n",
    "    \"fatigue_env_interaction\": 0.5,\n",
    "    \"is_metro\": 1\n",
    "}\n",
    "\n",
    "pred_value = predict_sleep_quality(sample_input)\n",
    "print(\"Predicted Sleep Quality Score:\", pred_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e040860",
   "metadata": {},
   "source": [
    "#### ***Inference: I test one full data record and confirm my function works as expected.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071387cf",
   "metadata": {},
   "source": [
    "## ***Create helper for clean prediction display***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ae21d",
   "metadata": {},
   "source": [
    "#### ***Inference: My app will use this to show friendly text instead of just numbers.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0a7f60",
   "metadata": {},
   "source": [
    "## ***Saving helper functions for Streamlit use***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5aa3da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model path resolved to: c:\\Users\\ASUS\\Desktop\\(SUPERVISED-1)ML_\\project\\Sleep Sense Predictor\\models\\ridge_model.pkl\n",
      "âœ… Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# file: app/predict_helper.py\n",
    "# encoding: utf-8\n",
    "\"\"\"\n",
    "SleepSense helper module:\n",
    "- predict_sleep_quality(input_dict) -> float score (0-100)\n",
    "- display_prediction(pred_value, language='English', verbose=False) -> message (localized)\n",
    "\n",
    "Save this file as app/predict_helper.py (UTF-8).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# âœ… FIXED MODEL PATH HANDLING â€” works in both Notebook and Streamlit\n",
    "try:\n",
    "    # if running as script or in Streamlit, __file__ exists\n",
    "    current_dir = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    # if running in Jupyter / interactive shell, fallback to current working directory\n",
    "    current_dir = Path(os.getcwd())\n",
    "\n",
    "# Define model path safely\n",
    "MODEL_PATH = current_dir.parent / \"models\" / \"ridge_model.pkl\"\n",
    "\n",
    "# print info (optional for debug)\n",
    "print(f\"âœ… Model path resolved to: {MODEL_PATH}\")\n",
    "\n",
    "# --- Load the model safely ---\n",
    "if MODEL_PATH.exists():\n",
    "    model = joblib.load(MODEL_PATH)\n",
    "    print(\"âœ… Model loaded successfully!\")\n",
    "else:\n",
    "    model = None\n",
    "    print(\"âš ï¸ Model file not found â€” please ensure ridge_model.pkl exists in /models/\")\n",
    "\n",
    "\n",
    "def predict_sleep_quality(input_data: dict) -> float:\n",
    "    \"\"\"\n",
    "    Convert input dict to DataFrame, ensure required columns, predict with the loaded model,\n",
    "    and return a rounded float score (0-100).\n",
    "    - input_data: dict with any subset of features. Missing features are filled with 0.\n",
    "    \"\"\"\n",
    "    _ensure_model()\n",
    "\n",
    "    # create single-row dataframe\n",
    "    x = pd.DataFrame([input_data])\n",
    "\n",
    "    # ensure all feature columns exist\n",
    "    for col in FEATURE_COLS:\n",
    "        if col not in x.columns:\n",
    "            x[col] = 0\n",
    "\n",
    "    # reorder columns to match model\n",
    "    x = x[FEATURE_COLS]\n",
    "\n",
    "    # some columns expected as numeric; try safe conversion\n",
    "    x = x.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "    # prediction\n",
    "    pred = _model.predict(x)[0]\n",
    "\n",
    "    # constrain to 0-100 and round\n",
    "    pred = float(pred)\n",
    "    pred = max(0.0, min(100.0, pred))\n",
    "    return round(pred, 2)\n",
    "\n",
    "\n",
    "def display_prediction(pred_value: float, language: str = 'English', verbose: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Return multilingual, human-friendly sleep interpretation for pred_value (0-100).\n",
    "    - language: full language name string (e.g., 'Hindi', 'Tamil', 'Bengali', 'English', etc.)\n",
    "    - verbose: if True, prints internal debug lines (useful during development)\n",
    "    \"\"\"\n",
    "\n",
    "    # small safety convert\n",
    "    try:\n",
    "        score = float(pred_value)\n",
    "    except Exception:\n",
    "        score = -9999.0\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ðŸ§® Predicted Sleep Quality Score: {score}\")\n",
    "        print(f\"ðŸŒ Language requested: {language}\")\n",
    "\n",
    "    # --- translations: full-language names (expandable) ---\n",
    "    translations = {\n",
    "        \"English\": {\"excellent\": \"Excellent Sleep Quality\", \"poor\": \"Poor Sleep Quality\",\n",
    "                    \"critical\": \"Critical Sleep Condition\", \"rest\": \"Take proper rest and reduce stress.\"},\n",
    "        \"Hindi\": {\"excellent\": \"à¤‰à¤¤à¥à¤•à¥ƒà¤·à¥à¤Ÿ à¤¨à¥€à¤‚à¤¦ à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾\", \"poor\": \"à¤•à¤®à¤œà¤¼à¥‹à¤° à¤¨à¥€à¤‚à¤¦ à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾\",\n",
    "                  \"critical\": \"à¤—à¤‚à¤­à¥€à¤° à¤¨à¥€à¤‚à¤¦ à¤¸à¥à¤¥à¤¿à¤¤à¤¿\", \"rest\": \"à¤…à¤šà¥à¤›à¥€ à¤¨à¥€à¤‚à¤¦ à¤²à¥‡à¤‚ à¤”à¤° à¤¤à¤¨à¤¾à¤µ à¤•à¤® à¤•à¤°à¥‡à¤‚à¥¤\"},\n",
    "        \"Bengali\": {\"excellent\": \"à¦šà¦®à§Žà¦•à¦¾à¦° à¦˜à§à¦®à§‡à¦° à¦®à¦¾à¦¨\", \"poor\": \"à¦¦à§à¦°à§à¦¬à¦² à¦˜à§à¦®à§‡à¦° à¦®à¦¾à¦¨\",\n",
    "                    \"critical\": \"à¦—à§à¦°à§à¦¤à¦° à¦˜à§à¦®à§‡à¦° à¦…à¦¬à¦¸à§à¦¥à¦¾\", \"rest\": \"à¦¬à¦¿à¦¶à§à¦°à¦¾à¦® à¦¨à¦¿à¦¨ à¦à¦¬à¦‚ à¦šà¦¾à¦ª à¦•à¦®à¦¾à¦¨à¥¤\"},\n",
    "        \"Tamil\": {\"excellent\": \"à®šà®¿à®±à®¨à¯à®¤ à®‰à®±à®•à¯à®•à®¤à¯ à®¤à®°à®®à¯\", \"poor\": \"à®®à¯‹à®šà®®à®¾à®© à®‰à®±à®•à¯à®•à®¤à¯ à®¤à®°à®®à¯\",\n",
    "                  \"critical\": \"à®•à®Ÿà¯à®®à¯ˆà®¯à®¾à®© à®‰à®±à®•à¯à®• à®¨à®¿à®²à¯ˆ\", \"rest\": \"à®¨à®©à¯à®±à®¾à®• à®‰à®±à®™à¯à®•à¯à®™à¯à®•à®³à¯ à®®à®±à¯à®±à¯à®®à¯ à®®à®©à®…à®´à¯à®¤à¯à®¤à®¤à¯à®¤à¯ˆ à®•à¯à®±à¯ˆà®¯à¯à®™à¯à®•à®³à¯.\"},\n",
    "        \"Telugu\": {\"excellent\": \"à°…à°¦à±à°­à±à°¤à°®à±ˆà°¨ à°¨à°¿à°¦à±à°° à°¨à°¾à°£à±à°¯à°¤\", \"poor\": \"à°ªà±‡à°¦ à°¨à°¿à°¦à±à°° à°¨à°¾à°£à±à°¯à°¤\",\n",
    "                   \"critical\": \"à°¤à±€à°µà±à°°à°®à±ˆà°¨ à°¨à°¿à°¦à±à°° à°¸à±à°¥à°¿à°¤à°¿\", \"rest\": \"à°¸à°°à±ˆà°¨ à°µà°¿à°¶à±à°°à°¾à°‚à°¤à°¿ à°¤à±€à°¸à±à°•à±‹à°‚à°¡à°¿ à°®à°°à°¿à°¯à± à°’à°¤à±à°¤à°¿à°¡à°¿à°¨à°¿ à°¤à°—à±à°—à°¿à°‚à°šà°‚à°¡à°¿.\"},\n",
    "        \"Kannada\": {\"excellent\": \"à²…à²¤à³à²¯à³à²¤à³à²¤à²® à²¨à²¿à²¦à³à²°à³† à²—à³à²£à²®à²Ÿà³à²Ÿ\", \"poor\": \"à²•à³†à²Ÿà³à²Ÿ à²¨à²¿à²¦à³à²°à³† à²—à³à²£à²®à²Ÿà³à²Ÿ\",\n",
    "                    \"critical\": \"à²—à²‚à²­à³€à²° à²¨à²¿à²¦à³à²°à³† à²¸à³à²¥à²¿à²¤à²¿\", \"rest\": \"à²’à²³à³à²³à³†à²¯ à²¨à²¿à²¦à³à²°à³† à²®à²¾à²¡à²¿ à²®à²¤à³à²¤à³ à²’à²¤à³à²¤à²¡à²µà²¨à³à²¨à³ à²•à²¡à²¿à²®à³† à²®à²¾à²¡à²¿.\"},\n",
    "        \"Malayalam\": {\"excellent\": \"à´®à´¿à´•à´šàµà´š à´‰à´±à´•àµà´• à´—àµà´£à´®àµ‡à´¨àµà´®\", \"poor\": \"à´¦àµà´°àµâ€à´¬à´²à´®à´¾à´¯ à´‰à´±à´•àµà´• à´—àµà´£à´®àµ‡à´¨àµà´®\",\n",
    "                      \"critical\": \"à´—àµ—à´°à´µà´®àµà´³àµà´³ à´‰à´±à´•àµà´• à´…à´µà´¸àµà´¥\", \"rest\": \"à´¶àµà´°à´¦àµà´§à´¯àµ‹à´Ÿàµ† à´µà´¿à´¶àµà´°à´®à´¿à´•àµà´•àµà´•à´¯àµà´‚ à´¸à´®àµà´®àµ¼à´¦àµà´¦à´‚ à´•àµà´±à´¯àµà´•àµà´•àµà´•à´¯àµà´‚ à´šàµ†à´¯àµà´¯àµà´•.\"},\n",
    "        \"Marathi\": {\"excellent\": \"à¤‰à¤¤à¥à¤•à¥ƒà¤·à¥à¤Ÿ à¤à¥‹à¤ª à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾\", \"poor\": \"à¤•à¤®à¥€ à¤à¥‹à¤ª à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾\",\n",
    "                    \"critical\": \"à¤—à¤‚à¤­à¥€à¤° à¤à¥‹à¤ª à¤¸à¥à¤¥à¤¿à¤¤à¥€\", \"rest\": \"à¤šà¤¾à¤‚à¤—à¤²à¥€ à¤à¥‹à¤ª à¤˜à¥à¤¯à¤¾ à¤†à¤£à¤¿ à¤¤à¤£à¤¾à¤µ à¤•à¤®à¥€ à¤•à¤°à¤¾.\"},\n",
    "        \"Punjabi\": {\"excellent\": \"à¨‰à¨¤à¨•à©à¨°à¨¿à¨¸à¨¼à¨Ÿ à¨¨à©€à¨‚à¨¦ à¨—à©à¨£à¨µà©±à¨¤à¨¾\", \"poor\": \"à¨–à¨°à¨¾à¨¬ à¨¨à©€à¨‚à¨¦ à¨—à©à¨£à¨µà©±à¨¤à¨¾\",\n",
    "                    \"critical\": \"à¨—à©°à¨­à©€à¨° à¨¨à©€à¨‚à¨¦ à¨¦à©€ à¨¸à¨¥à¨¿à¨¤à©€\", \"rest\": \"à¨šà©°à¨—à©€ à¨¨à©€à¨‚à¨¦ à¨•à¨°à©‹ à¨…à¨¤à©‡ à¨¤à¨£à¨¾à¨… à¨˜à¨Ÿà¨¾à¨“à¥¤\"},\n",
    "        \"Gujarati\": {\"excellent\": \"àª‰àª¤à«àª•à«ƒàª·à«àªŸ àª¨àª¿àª‚àª¦à«àª°àª¾àª¨à«€ àª—à«àª£àªµàª¤à«àª¤àª¾\", \"poor\": \"àª¨àª¬àª³à«€ àª¨àª¿àª‚àª¦à«àª°àª¾àª¨à«€ àª—à«àª£àªµàª¤à«àª¤àª¾\",\n",
    "                     \"critical\": \"àª—àª‚àª­à«€àª° àª¨àª¿àª‚àª¦à«àª°àª¾ àª¸à«àª¥àª¿àª¤àª¿\", \"rest\": \"àª¸àª¾àª°à«€ àªŠàª‚àª˜ àª²à«‹ àª…àª¨à«‡ àª¤àª£àª¾àªµ àª˜àªŸàª¾àª¡à«‹.\"},\n",
    "        \"Odia\": {\"excellent\": \"à¬‰à¬¤à­à¬•à­ƒà¬·à­à¬Ÿ à¬¨à¬¿à¬¦à­à¬°à¬¾ à¬—à­à¬£à¬¤à¬¾\", \"poor\": \"à¬¦à­à¬°à­à¬¬à¬³ à¬¨à¬¿à¬¦à­à¬°à¬¾ à¬—à­à¬£à¬¤à¬¾\",\n",
    "                 \"critical\": \"à¬—à­à¬°à­à¬¤à¬° à¬¨à¬¿à¬¦à­à¬°à¬¾ à¬…à¬¬à¬¸à­à¬¥à¬¾\", \"rest\": \"à¬­à¬² à¬¸à­à¬‡à¬ªà¬¾à¬°à¬¿à¬¬à­‡ à¬à¬¬à¬‚ à¬šà¬¿à¬¨à­à¬¤à¬¾ à¬•à¬®à¬¾à¬¨à­à¬¤à­à¥¤\"},\n",
    "        \"Assamese\": {\"excellent\": \"à¦‰à¦¤à§à¦¤à¦® à¦˜à§à¦®à§° à¦—à§à¦£à¦®à¦¾à¦¨\", \"poor\": \"à¦¦à§à§°à§à¦¬à¦² à¦˜à§à¦®à§° à¦—à§à¦£à¦®à¦¾à¦¨\",\n",
    "                     \"critical\": \"à¦—à¦­à§€à§° à¦˜à§à¦®à§° à¦…à§±à¦¸à§à¦¥à¦¾\", \"rest\": \"à¦­à¦¾à¦²à¦•à§ˆ à¦¬à¦¿à¦¶à§à¦°à¦¾à¦® à¦²à¦“à¦• à¦†à§°à§ à¦šà¦¾à¦ª à¦•à¦®à¦¾à¦“à¦•à¥¤\"},\n",
    "        \"Nepali\": {\"excellent\": \"à¤‰à¤¤à¥à¤•à¥ƒà¤·à¥à¤Ÿ à¤¨à¤¿à¤¦à¥à¤°à¤¾ à¤—à¥à¤£à¤¸à¥à¤¤à¤°\", \"poor\": \"à¤•à¤®à¤œà¥‹à¤° à¤¨à¤¿à¤¦à¥à¤°à¤¾ à¤—à¥à¤£à¤¸à¥à¤¤à¤°\",\n",
    "                   \"critical\": \"à¤—à¤‚à¤­à¥€à¤° à¤¨à¤¿à¤¦à¥à¤°à¤¾ à¤¸à¥à¤¥à¤¿à¤¤à¤¿\", \"rest\": \"à¤°à¤¾à¤®à¥à¤°à¤°à¥€ à¤¨à¤¿à¤¦à¥à¤°à¤¾ à¤²à¤¿à¤¨à¥à¤¹à¥‹à¤¸à¥ à¤° à¤¤à¤¨à¤¾à¤µ à¤˜à¤Ÿà¤¾à¤‰à¤¨à¥à¤¹à¥‹à¤¸à¥à¥¤\"},\n",
    "        \"Urdu\": {\"excellent\": \"Ø¨ÛØªØ±ÛŒÙ† Ù†ÛŒÙ†Ø¯ Ú©Ø§ Ù…Ø¹ÛŒØ§Ø±\", \"poor\": \"Ù†Ø§Ù‚Øµ Ù†ÛŒÙ†Ø¯ Ú©Ø§ Ù…Ø¹ÛŒØ§Ø±\",\n",
    "                 \"critical\": \"Ø³Ù†Ú¯ÛŒÙ† Ù†ÛŒÙ†Ø¯ Ú©ÛŒ Ø­Ø§Ù„Øª\", \"rest\": \"Ø§Ú†Ú¾ÛŒ Ù†ÛŒÙ†Ø¯ Ù„ÛŒÚº Ø§ÙˆØ± Ø¯Ø¨Ø§Ø¤ Ú©Ù… Ú©Ø±ÛŒÚºÛ”\"},\n",
    "        \"Sindhi\": {\"excellent\": \"Ø¨Ù‡ØªØ±ÙŠÙ† Ù†Ù†ÚŠ Ø¬Ùˆ Ù…Ø¹ÙŠØ§Ø±\", \"poor\": \"ÚªÙ…Ø²ÙˆØ± Ù†Ù†ÚŠ Ø¬Ùˆ Ù…Ø¹ÙŠØ§Ø±\",\n",
    "                   \"critical\": \"Ø³Ù†Ú¯ÙŠÙ† Ù†Ù†ÚŠ Ø­Ø§Ù„Øª\", \"rest\": \"Ø³ÙºÙŠ Ù†Ù†ÚŠ ÙˆÙºÙˆ Û½ Ø¯Ù»Ø§Ø¡Ù Ú¯Ù‡Ù½Ø§ÙŠÙˆ.\"},\n",
    "        \"Dogri\": {\"excellent\": \"à¤‰à¤¤à¥à¤¤à¤® à¤¨à¥€à¤‚à¤¦ à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾\", \"poor\": \"à¤•à¤®à¤œà¤¼à¥‹à¤° à¤¨à¥€à¤‚à¤¦ à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾\",\n",
    "                  \"critical\": \"à¤—à¤‚à¤­à¥€à¤° à¤¨à¥€à¤‚à¤¦ à¤¸à¥à¤¥à¤¿à¤¤à¤¿\", \"rest\": \"à¤…à¤šà¥à¤›à¥€ à¤¨à¥€à¤‚à¤¦ à¤²à¥‡à¤‚ à¤”à¤° à¤¤à¤¨à¤¾à¤µ à¤•à¤® à¤•à¤°à¥‡à¤‚à¥¤\"},\n",
    "        \"Maithili\": {\"excellent\": \"à¤‰à¤¤à¥à¤¤à¤® à¤¨à¥€à¤‚à¤¦ à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾\", \"poor\": \"à¤•à¤®à¤œà¤¼à¥‹à¤° à¤¨à¥€à¤‚à¤¦ à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾\",\n",
    "                     \"critical\": \"à¤—à¤‚à¤­à¥€à¤° à¤¨à¥€à¤‚à¤¦ à¤¸à¥à¤¥à¤¿à¤¤à¤¿\", \"rest\": \"à¤…à¤šà¥à¤›à¥‡ à¤¸à¥‡ à¤†à¤°à¤¾à¤® à¤•à¤°à¥‡à¤‚ à¤”à¤° à¤¤à¤¨à¤¾à¤µ à¤˜à¤Ÿà¤¾à¤à¤‚à¥¤\"},\n",
    "        \"Konkani\": {\"excellent\": \"à¤‰à¤¤à¥à¤•à¥ƒà¤·à¥à¤Ÿ à¤à¥‹à¤ª à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾\", \"poor\": \"à¤–à¤°à¤¾à¤¬ à¤à¥‹à¤ª à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾\",\n",
    "                    \"critical\": \"à¤—à¤‚à¤­à¥€à¤° à¤à¥‹à¤ª à¤¸à¥à¤¥à¤¿à¤¤à¥€\", \"rest\": \"à¤¯à¥‹à¤—à¥à¤¯ à¤µà¤¿à¤¶à¥à¤°à¤¾à¤‚à¤¤à¥€ à¤˜à¥à¤¯à¤¾ à¤†à¤£à¤¿ à¤¤à¤¾à¤£ à¤•à¤®à¥€ à¤•à¤°à¤¾.\"},\n",
    "        \"Manipuri\": {\"excellent\": \"ê¯‘ê¯¦ê¯ ê¯‡ê¯¥ê¯ê¯ê¯¤ê¯¡ ê¯…ê¯¤ê¯—ê¯”ê¯¥ ê¯„ê¯¥ê¯¡ê¯…ê¯¥ê¯¡\", \"poor\": \"ê¯‹ê¯¤ê¯¡ê¯ˆê¯¥ê¯¡ ê¯…ê¯¤ê¯—ê¯”ê¯¥ ê¯„ê¯¥ê¯¡ê¯…ê¯¥ê¯¡\",\n",
    "                    \"critical\": \"ê¯’ê¯”ê¯¤ê¯• ê¯…ê¯¤ê¯—ê¯”ê¯¥ ê¯„ê¯¥ê¯¡ê¯…ê¯¥ê¯¡\", \"rest\": \"ê¯†ê¯¥ê¯Žê¯• ê¯…ê¯¤ê¯—ê¯”ê¯¥ ê¯„ê¯¥ê¯¡ê¯…ê¯¥ê¯¡ ê¯ƒê¯‡ê¯ê¯—ê¯¤ ê¯ƒê¯‡ê¯© ê¯ê¯£ê¯¡ê¯…ê¯¥ ê¯ˆê¯ªê¯—ê¯¤.\"},\n",
    "        \"Sanskrit\": {\"excellent\": \"à¤‰à¤¤à¥à¤¤à¤®à¤¾ à¤¨à¤¿à¤¦à¥à¤°à¤¾\", \"poor\": \"à¤¨à¥€à¤šà¤¾ à¤¨à¤¿à¤¦à¥à¤°à¤¾\",\n",
    "                     \"critical\": \"à¤—à¤‚à¤­à¥€à¤° à¤¨à¤¿à¤¦à¥à¤°à¤¾\", \"rest\": \"à¤µà¤¿à¤¶à¥à¤°à¤¾à¤®à¤‚ à¤•à¥à¤°à¥à¤¤ à¤µ à¤¤à¤¨à¤¾à¤µà¤‚ à¤¨à¥à¤¯à¥‚à¤¨à¤‚ à¤•à¥à¤°à¥à¤¤à¥¤\"},\n",
    "        \"Bodo\": {\"excellent\": \"à¤‰à¤¤à¥à¤¤à¤® à¤¨à¤¿à¤‚à¤¦à¤° à¤—à¥à¤¨à¤®à¤¾à¤¨\", \"poor\": \"à¤•à¤®à¤œà¥‹à¤° à¤¨à¤¿à¤‚à¤¦à¤° à¤—à¥à¤¨à¤®à¤¾à¤¨\",\n",
    "                 \"critical\": \"à¤—à¤‚à¤­à¥€à¤° à¤¨à¤¿à¤‚à¤¦à¤° à¤¸à¥à¤¥à¤¿à¤¤à¤¿\", \"rest\": \"à¤­à¤¾à¤² à¤¸à¥à¤‡ à¤† à¤¤à¤¨à¤¾à¤µ à¤—à¥‹à¤° à¤¹à¥‹à¥¤\"},\n",
    "        \"Bhojpuri\": {\"excellent\": \"à¤¬à¤¢à¤¼à¤¿à¤¯à¤¾ à¤¨à¥€à¤‚à¤¦ à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾\", \"poor\": \"à¤–à¤°à¤¾à¤¬ à¤¨à¥€à¤‚à¤¦ à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾\",\n",
    "                     \"critical\": \"à¤—à¤‚à¤­à¥€à¤° à¤¨à¥€à¤‚à¤¦ à¤¸à¥à¤¥à¤¿à¤¤à¤¿\", \"rest\": \"à¤…à¤šà¥à¤›à¥‡ à¤¸à¥‡ à¤†à¤°à¤¾à¤® à¤•à¤°à¥€à¤‚, à¤¤à¤¨à¤¾à¤µ à¤† à¤®à¥‹à¤¬à¤¾à¤‡à¤² à¤Ÿà¤¾à¤‡à¤® à¤˜à¤Ÿà¤¾à¤ˆà¤‚à¥¤\"}\n",
    "    }\n",
    "\n",
    "    # fallback\n",
    "    lang_dict = translations.get(language, translations[\"English\"])\n",
    "\n",
    "    # Choose message based on score (30-level logic)\n",
    "    # messages append localized 'rest' advice from lang_dict\n",
    "    rest_text = lang_dict.get('rest', translations['English']['rest'])\n",
    "\n",
    "    # Note: keep conditions exactly as designed for interpretability\n",
    "    if score >= 99:\n",
    "        msg = f\"ðŸ’Ž {lang_dict['excellent']} ({score}) â€” Elite sleeper, perfect balance! {rest_text}\"\n",
    "    elif 95 <= score < 99:\n",
    "        msg = f\"ðŸŒ• {lang_dict['excellent']} ({score}) â€” Perfect lifestyle balance. {rest_text}\"\n",
    "    elif 92 <= score < 95:\n",
    "        msg = f\"âœ¨ {lang_dict['excellent']} ({score}) â€” Near perfect, slight improvement possible. {rest_text}\"\n",
    "    elif 88 <= score < 92:\n",
    "        msg = f\"ðŸŒ™ {lang_dict['excellent']} ({score}) â€” Calm routine and minimal stress. {rest_text}\"\n",
    "    elif 85 <= score < 88:\n",
    "        msg = f\"ðŸ’š {lang_dict['excellent']} ({score}) â€” Stable routine with minor fatigue. {rest_text}\"\n",
    "    elif 80 <= score < 85:\n",
    "        msg = f\"ðŸ™‚ {lang_dict['excellent']} ({score}) â€” Healthy sleep pattern, keep it up. {rest_text}\"\n",
    "    elif 75 <= score < 80:\n",
    "        msg = f\"ðŸ˜´ {lang_dict['excellent']} ({score}) â€” Mild irregularity in sleep hours. {rest_text}\"\n",
    "    elif 70 <= score < 75:\n",
    "        msg = f\"ðŸŸ© {lang_dict['poor']} ({score}) â€” Moderate lifestyle balance. {rest_text}\"\n",
    "    elif 66 <= score < 70:\n",
    "        msg = f\"ðŸŸ¢ {lang_dict['poor']} ({score}) â€” Manageable sleep, occasional stress. {rest_text}\"\n",
    "    elif 63 <= score < 66:\n",
    "        msg = f\"ðŸ˜ {lang_dict['poor']} ({score}) â€” Average pattern, needs improvement. {rest_text}\"\n",
    "    elif 60 <= score < 63:\n",
    "        msg = f\"ðŸŸ¡ {lang_dict['poor']} ({score}) â€” Irregular sleep time, fatigue visible. {rest_text}\"\n",
    "    elif 56 <= score < 60:\n",
    "        msg = f\"ðŸŸ  {lang_dict['poor']} ({score}) â€” Body fatigue and rest gap detected. {rest_text}\"\n",
    "    elif 52 <= score < 56:\n",
    "        msg = f\"âš ï¸ {lang_dict['poor']} ({score}) â€” Minor imbalance due to stress. {rest_text}\"\n",
    "    elif 48 <= score < 52:\n",
    "        msg = f\"ðŸ”´ {lang_dict['poor']} ({score}) â€” Regular disturbance noticed. {rest_text}\"\n",
    "    elif 45 <= score < 48:\n",
    "        msg = f\"ðŸš§ {lang_dict['poor']} ({score}) â€” Inconsistent sleep or overwork. {rest_text}\"\n",
    "    elif 42 <= score < 45:\n",
    "        msg = f\"â˜ï¸ {lang_dict['poor']} ({score}) â€” Urban fatigue and noise impact. {rest_text}\"\n",
    "    elif 38 <= score < 42:\n",
    "        msg = f\"ðŸ’¤ {lang_dict['poor']} ({score}) â€” Restless pattern, low deep sleep. {rest_text}\"\n",
    "    elif 35 <= score < 38:\n",
    "        msg = f\"âš™ï¸ {lang_dict['poor']} ({score}) â€” Late-night workload affecting rest. {rest_text}\"\n",
    "    elif 30 <= score < 35:\n",
    "        msg = f\"ðŸ”¥ {lang_dict['poor']} ({score}) â€” Stress dominated routine. {rest_text}\"\n",
    "    elif 28 <= score < 30:\n",
    "        msg = f\"ðŸ§  {lang_dict['poor']} ({score}) â€” Overthinking before bed. {rest_text}\"\n",
    "    elif 25 <= score < 28:\n",
    "        msg = f\"ðŸ“± {lang_dict['poor']} ({score}) â€” Excessive screen use before sleep. {rest_text}\"\n",
    "    elif 22 <= score < 25:\n",
    "        msg = f\"ðŸ’¼ {lang_dict['poor']} ({score}) â€” Overwork causing low rest. {rest_text}\"\n",
    "    elif 18 <= score < 22:\n",
    "        msg = f\"ðŸ¥± {lang_dict['poor']} ({score}) â€” Fatigue and incomplete rest. {rest_text}\"\n",
    "    elif 15 <= score < 18:\n",
    "        msg = f\"ðŸš¨ {lang_dict['critical']} ({score}) â€” Exhaustion and anxiety possible. {rest_text}\"\n",
    "    elif 12 <= score < 15:\n",
    "        msg = f\"ðŸ’€ {lang_dict['critical']} ({score}) â€” Severe sleep deprivation stage. {rest_text}\"\n",
    "    elif 8 <= score < 12:\n",
    "        msg = f\"ðŸ©¸ {lang_dict['critical']} ({score}) â€” Signs of chronic insomnia. {rest_text}\"\n",
    "    elif 5 <= score < 8:\n",
    "        msg = f\"ðŸ’¤ {lang_dict['critical']} ({score}) â€” Almost no restful sleep. {rest_text}\"\n",
    "    elif 2 <= score < 5:\n",
    "        msg = f\"ðŸ•¯ï¸ {lang_dict['critical']} ({score}) â€” Body energy collapse detected. {rest_text}\"\n",
    "    elif 0 < score < 2:\n",
    "        msg = f\"âš°ï¸ {lang_dict['critical']} ({score}) â€” Extreme lack of sleep. {rest_text}\"\n",
    "    else:\n",
    "        msg = f\"âŒ Invalid Sleep Score ({pred_value}) â€” Please check input.\"\n",
    "\n",
    "    if verbose:\n",
    "        print(\"â†’ Final message:\", msg)\n",
    "\n",
    "    return msg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9a658f",
   "metadata": {},
   "source": [
    "## ***Inference: Now my Streamlit app can import this helper file directly for live predictions.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b590a6",
   "metadata": {},
   "source": [
    "## ***Summary***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ea395",
   "metadata": {},
   "source": [
    "- The Ridge model is loaded and working perfectly for prediction.  \n",
    "- I created helper functions to handle input and display results clearly.  \n",
    "- The same functions are saved in `predict_helper.py` for the Streamlit app.  \n",
    "- Everything is ready to move into **`streamlit_app.py`** to build the interactive user interface.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
